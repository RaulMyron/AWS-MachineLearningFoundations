{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratório 3.7 - Notebook do aluno"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visão geral\n",
    "\n",
    "Este laboratório é uma continuação dos laboratórios guiados do Módulo 3.\n",
    "\n",
    "Neste laboratório, você criará um trabalho de ajuste de hiperparâmetros para ajustar o modelo criado anteriormente. Depois, você comparará as métricas dos dois modelos.\n",
    "\n",
    "\n",
    "## Introdução ao cenário do negócio\n",
    "\n",
    "Você trabalha para um provedor de serviços médicos e deseja melhorar a detecção de anormalidades em pacientes ortopédicos. \n",
    "\n",
    "Você tem a incumbência de resolver esse problema usando machine learning (ML). Você tem acesso a um conjunto de dados que contém seis funcionalidades biomecânicas (componentes) e um alvo (target) de *normal* (normal) ou *abnormal* (anormal). Você pode usar esse conjunto de dados (dataset) para treinar um modelo de ML para prever se um paciente terá uma anomalia.\n",
    "\n",
    "\n",
    "## Sobre esse conjunto de dados (dataset)\n",
    "\n",
    "Esse conjunto de dados biomédicos foi criado pelo Dr. Henrique da Mota durante um período de residência médica no Group of Applied Research in Orthopaedics (GARO) do Centre Médico-Chirurgical de Réadaptation des Massues em Lyon, na França. Os dados foram organizados em duas tarefas de classificação diferentes, mas relacionadas. \n",
    "\n",
    "A primeira tarefa consiste em classificar os pacientes como pertencentes a uma das três categorias a seguir: \n",
    "\n",
    "- *Normal* (Normal) (100 pacientes)\n",
    "- *Disk Hernia* (Hérnia de disco) (60 pacientes)\n",
    "- *Spondylolisthesis* (Espondilolistese) (150 pacientes)\n",
    "\n",
    "Para a segunda tarefa, as categorias *Disk Hernia* (Hérnia de disco) e *Spondylolisthesis* (Espondilolistese) foram mescladas em uma única categoria, rotulada como *abnormal* (anormal). Portanto, a segunda tarefa consiste em classificar os pacientes como pertencentes a uma das categorias: *Normal* (Normal) (100 pacientes) ou *Abnormal* (Anormal) (210 pacientes).\n",
    "\n",
    "\n",
    "## Informações dos atributos\n",
    "\n",
    "Cada paciente é representado no conjunto de dados (dataset) por seis atributos biomecânicos derivados da forma e da orientação da pelve e da coluna lombar (nesta ordem): \n",
    "\n",
    "- Incidência pélvica\n",
    "- Inclinação pélvica\n",
    "- Ângulo da lordose lombar\n",
    "- Inclinação sacral\n",
    "- Raio pélvico\n",
    "- Grau de espondilolistese\n",
    "\n",
    "A convenção a seguir é usada para os rótulos de classe (labels): \n",
    "- DH (hérnia de disco)\n",
    "- Espondilolistese (SL)\n",
    "- Normal (NO) \n",
    "- Anormal (AB)\n",
    "\n",
    "\n",
    "Para obter mais informações sobre esse conjunto de dados (dataset), consulte a [página da Web Conjunto de dados de coluna vertebral](http://archive.ics.uci.edu/ml/datasets/Vertebral+Column).\n",
    "\n",
    "\n",
    "## Atribuições do conjunto de dados (dataset)\n",
    "\n",
    "Esse conjunto de dados (dataset) foi obtido de:\n",
    "Dua, D. e Graff, C. (2019). repositório UCI Machine Learning (http://archive.ics.uci.edu/ml). Irvine, CA: University of California, School of Information and Computer Science.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuração do laboratório\n",
    "\n",
    "Como a solução é dividida em vários laboratórios no módulo, você executará as seguintes células para poder carregar os dados e treinar o modelo a ser implantado.\n",
    "\n",
    "**Observação:** a configuração pode demorar até cinco minutos para ser concluída."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação dos dados, treinamento, teste e validação do modelo\n",
    "\n",
    "Ao executar as seguintes células, os dados serão importados, e o modelo será treinado, testado e validado. Ele estará pronto para uso. \n",
    "\n",
    "**Observação:** as células a seguir representam as principais etapas dos laboratórios anteriores.\n",
    "\n",
    "Para ajustar o modelo, ele deve estar pronto. Você poderá então ajustá-lo com hiperparâmetros na etapa 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket='c117523a2804664l6884813t1w571208947195-labbucket-1yte2gh3rtlw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "import warnings, requests, zipfile, io\n",
    "warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observação:** a célula leva, aproximadamente, **10** minutos para ser executada. Observe o código e como ele é processado. Isso ajudará você a entender melhor o que está acontecendo em segundo plano. Lembre-se de que esta célula conclui todas as etapas que você realizou em laboratórios anteriores neste módulo, incluindo:\n",
    " - Importar os dados\n",
    " - Carregar os dados em um dataframe\n",
    " - Dividir os dados em conjuntos de dados de treinamento, teste e validação\n",
    " - Fazer upload dos conjuntos de dados divididos no S3\n",
    " - Treinar, testar e validar o modelo com os conjuntos de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def plot_roc(test_labels, target_predicted_binary):\n",
    "    TN, FP, FN, TP = confusion_matrix(test_labels, target_predicted_binary).ravel()\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    Sensitivity  = float(TP)/(TP+FN)*100\n",
    "    # Specificity or true negative rate\n",
    "    Specificity  = float(TN)/(TN+FP)*100\n",
    "    # Precision or positive predictive value\n",
    "    Precision = float(TP)/(TP+FP)*100\n",
    "    # Negative predictive value\n",
    "    NPV = float(TN)/(TN+FN)*100\n",
    "    # Fall out or false positive rate\n",
    "    FPR = float(FP)/(FP+TN)*100\n",
    "    # False negative rate\n",
    "    FNR = float(FN)/(TP+FN)*100\n",
    "    # False discovery rate\n",
    "    FDR = float(FP)/(TP+FP)*100\n",
    "    # Overall accuracy\n",
    "    ACC = float(TP+TN)/(TP+FP+FN+TN)*100\n",
    "\n",
    "    print(f\"Sensitivity or TPR: {Sensitivity}%\")    \n",
    "    print(f\"Specificity or TNR: {Specificity}%\") \n",
    "    print(f\"Precision: {Precision}%\")   \n",
    "    print(f\"Negative Predictive Value: {NPV}%\")  \n",
    "    print( f\"False Positive Rate: {FPR}%\") \n",
    "    print(f\"False Negative Rate: {FNR}%\")  \n",
    "    print(f\"False Discovery Rate: {FDR}%\" )\n",
    "    print(f\"Accuracy: {ACC}%\") \n",
    "\n",
    "    test_labels = test.iloc[:,0];\n",
    "    print(\"Validation AUC\", roc_auc_score(test_labels, target_predicted_binary) )\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(test_labels, target_predicted_binary)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % (roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    # create the axis of thresholds (scores)\n",
    "    ax2 = plt.gca().twinx()\n",
    "    ax2.plot(fpr, thresholds, markeredgecolor='r',linestyle='dashed', color='r')\n",
    "    ax2.set_ylabel('Threshold',color='r')\n",
    "    ax2.set_ylim([thresholds[-1],thresholds[0]])\n",
    "    ax2.set_xlim([fpr[0],fpr[-1]])\n",
    "\n",
    "    print(plt.figure())\n",
    "\n",
    "def plot_confusion_matrix(test_labels, target_predicted):\n",
    "    matrix = confusion_matrix(test_labels, target_predicted)\n",
    "    df_confusion = pd.DataFrame(matrix)\n",
    "    colormap = sns.color_palette(\"BrBG\", 10)\n",
    "    sns.heatmap(df_confusion, annot=True, fmt='.2f', cbar=None, cmap=colormap)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel(\"True Class\")\n",
    "    plt.xlabel(\"Predicted Class\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "f_zip = 'http://archive.ics.uci.edu/ml/machine-learning-databases/00212/vertebral_column_data.zip'\n",
    "r = requests.get(f_zip, stream=True)\n",
    "Vertebral_zip = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "Vertebral_zip.extractall()\n",
    "\n",
    "data = arff.loadarff('column_2C_weka.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "\n",
    "class_mapper = {b'Abnormal':1,b'Normal':0}\n",
    "df['class']=df['class'].replace(class_mapper)\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df = df[cols]\n",
    "\n",
    "train, test_and_validate = train_test_split(df, test_size=0.2, random_state=42, stratify=df['class'])\n",
    "test, validate = train_test_split(test_and_validate, test_size=0.5, random_state=42, stratify=test_and_validate['class'])\n",
    "\n",
    "prefix='lab3'\n",
    "\n",
    "train_file='vertebral_train.csv'\n",
    "test_file='vertebral_test.csv'\n",
    "validate_file='vertebral_validate.csv'\n",
    "\n",
    "s3_resource = boto3.Session().resource('s3')\n",
    "def upload_s3_csv(filename, folder, dataframe):\n",
    "    csv_buffer = io.StringIO()\n",
    "    dataframe.to_csv(csv_buffer, header=False, index=False )\n",
    "    s3_resource.Bucket(bucket).Object(os.path.join(prefix, folder, filename)).put(Body=csv_buffer.getvalue())\n",
    "\n",
    "upload_s3_csv(train_file, 'train', train)\n",
    "upload_s3_csv(test_file, 'test', test)\n",
    "upload_s3_csv(validate_file, 'validate', validate)\n",
    "\n",
    "container = retrieve('xgboost',boto3.Session().region_name,'1.0-1')\n",
    "\n",
    "hyperparams={\"num_round\":\"42\",\n",
    "             \"eval_metric\": \"auc\",\n",
    "             \"objective\": \"binary:logistic\",\n",
    "             \"silent\" : 1}\n",
    "\n",
    "s3_output_location=\"s3://{}/{}/output/\".format(bucket,prefix)\n",
    "xgb_model=sagemaker.estimator.Estimator(container,\n",
    "                                       sagemaker.get_execution_role(),\n",
    "                                       instance_count=1,\n",
    "                                       instance_type='ml.m5.2xlarge',\n",
    "                                       output_path=s3_output_location,\n",
    "                                        hyperparameters=hyperparams,\n",
    "                                        sagemaker_session=sagemaker.Session())\n",
    "\n",
    "train_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/train/\".format(bucket,prefix,train_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "validate_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/validate/\".format(bucket,prefix,validate_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "data_channels = {'train': train_channel, 'validation': validate_channel}\n",
    "\n",
    "xgb_model.fit(inputs=data_channels, logs=False)\n",
    "\n",
    "batch_X = test.iloc[:,1:];\n",
    "\n",
    "batch_X_file='batch-in.csv'\n",
    "upload_s3_csv(batch_X_file, 'batch-in', batch_X)\n",
    "\n",
    "batch_output = \"s3://{}/{}/batch-out/\".format(bucket,prefix)\n",
    "batch_input = \"s3://{}/{}/batch-in/{}\".format(bucket,prefix,batch_X_file)\n",
    "\n",
    "xgb_transformer = xgb_model.transformer(instance_count=1,\n",
    "                                       instance_type='ml.m5.2xlarge',\n",
    "                                       strategy='MultiRecord',\n",
    "                                       assemble_with='Line',\n",
    "                                       output_path=batch_output)\n",
    "\n",
    "xgb_transformer.transform(data=batch_input,\n",
    "                         data_type='S3Prefix',\n",
    "                         content_type='text/csv',\n",
    "                         split_type='Line')\n",
    "xgb_transformer.wait(logs=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 1: Obtenção das estatísticas do modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de ajustar o modelo, familiarize-se novamente com as métricas do modelo atual.\n",
    "\n",
    "A configuração executou uma previsão em lote. Portanto, você deve ler os resultados do Amazon Simple Storage Service (Amazon S3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=bucket, Key=\"{}/batch-out/{}\".format(prefix,'batch-in.csv.out'))\n",
    "target_predicted = pd.read_csv(io.BytesIO(obj['Body'].read()),names=['class'])\n",
    "\n",
    "def binary_convert(x):\n",
    "    threshold = 0.5\n",
    "    if x > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "target_predicted_binary = target_predicted['class'].apply(binary_convert)\n",
    "test_labels = test.iloc[:,0]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trace a matriz de confusão (confusion matrix) e a curva da característica de operação do receptor (ROC) para o modelo original.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(test_labels, target_predicted_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(test_labels, target_predicted_binary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse gráfico fornece um ponto de partida. Faça uma anotação da *Área de validação sob a curva (AUC)*. Você a usará mais tarde para verificar se seu modelo ajustado é melhor. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 2: Criar um trabalho de ajuste de hiperparâmetros\n",
    "\n",
    "Um trabalho de ajuste de hiperparâmetros pode demorar várias horas para ser concluído, dependendo dos intervalos de valores que você fornecer. Para simplificar essa tarefa, os parâmetros usados nesta etapa são um subconjunto dos intervalos recomendados. Eles foram ajustados para fornecer bons resultados neste laboratório, sem levar várias horas para serem concluídos.\n",
    "\n",
    "Para obter mais informações sobre os parâmetros a serem ajustados para XGBoost, consulte [Ajustar um modelo XGBoost](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-tuning.html) na documentação da AWS."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como essa próxima célula pode levar cerca de **45** minutos para ser executada, prossiga e execute a célula. Você examinará o que está ocorrendo e por que esses intervalos de hiperparâmetros foram escolhidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role=sagemaker.get_execution_role(), \n",
    "                                    instance_count= 1, # make sure you have limit set for these instances\n",
    "                                    instance_type='ml.m4.xlarge', \n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=sagemaker.Session())\n",
    "\n",
    "\n",
    "xgb.set_hyperparameters(eval_metric='error@.40',\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=42)\n",
    "\n",
    "hyperparameter_ranges = {'alpha': ContinuousParameter(0, 100),\n",
    "                         'min_child_weight': ContinuousParameter(1, 5),\n",
    "                         'subsample': ContinuousParameter(0.5, 1),\n",
    "                         'eta': ContinuousParameter(0.1, 0.3),  \n",
    "                         'num_round': IntegerParameter(1,50)\n",
    "                         }\n",
    "\n",
    "objective_metric_name = 'validation:error'\n",
    "objective_type = 'Minimize'\n",
    "\n",
    "tuner = HyperparameterTuner(xgb,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs=10, # Set this to 10 or above depending upon budget & available time.\n",
    "                            max_parallel_jobs=1,\n",
    "                            objective_type=objective_type,\n",
    "                            early_stopping_type='Auto')\n",
    "\n",
    "tuner.fit(inputs=data_channels, include_cls_metadata=False)\n",
    "tuner.wait()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, você criará o modelo que deseja ajustar.\n",
    "\n",
    "```\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                   role=sagemaker.get_execution_role(), \n",
    "                                   instance_count= 1, # verifique se há limite definido para essas instâncias\n",
    "                                   instance_type='ml.m4.xlarge', \n",
    "                                   output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                   sagemaker_session=sagemaker.Session())\n",
    "\n",
    "xgb.set_hyperparameters(eval_metric='[error@.40]',\n",
    "                        objective='binary:logistic',\n",
    "                        num_round=42)\n",
    "\n",
    "```                        \n",
    "\n",
    "Observe que a *eval_metric* do modelo foi alterada para *error@.40*, com o objetivo de minimizar esse valor. \n",
    "\n",
    "**error** é a taxa de erro da classificação binária. Ela é calculada como *#(wrong cases)/#(all cases)* (n.º de casos incorretos)/(n.º total de casos). Para predições, a avaliação considerará as instâncias que têm um valor de predição maior do que 0,4 como instâncias positivas e as outras como instâncias negativas.\n",
    "\n",
    "Em seguida, você deverá especificar os hiperparâmetros que deseja ajustar, além dos intervalos que você deverá selecionar para cada parâmetro.\n",
    "\n",
    "Os hiperparâmetros que têm o maior efeito nas métricas objetivas do XGBoost são: \n",
    "\n",
    "- alpha\n",
    "- min_child_weight\n",
    "- subsample\n",
    "- eta\n",
    "- num_round \n",
    "\n",
    "Os intervalos de ajuste (tuning ranges) recomendados podem ser encontrados na documentação da AWS em [Ajustando um modelo XGBoost](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-tuning.html).\n",
    "\n",
    "Para este laboratório, você usará um *subconjunto* de valores. Esses valores foram obtidos executando o trabalho de ajuste (tuning job) com o intervalo completo e, em seguida, minimizando o intervalo para que você possa usar menos iterações para obter melhor desempenho. Embora essa prática não seja estritamente realista, ela impede que você espere várias horas neste laboratório até que o trabalho de ajuste seja concluído.\n",
    "\n",
    "```\n",
    "hyperparameter_ranges = {'alpha': ContinuousParameter(0, 100),\n",
    "                         'min_child_weight': ContinuousParameter(1, 5),\n",
    "                         'subsample': ContinuousParameter(0.5, 1),\n",
    "                         'eta': ContinuousParameter(0.1, 0.3),  \n",
    "                         'num_round': IntegerParameter(1,50)\n",
    "                         }\n",
    "```\n",
    "\n",
    "\n",
    "Você deve especificar como está classificando o modelo. Você pode usar várias métricas objetivas diferentes, sendo que um subconjunto se aplica a um problema de classificação binária. Como a métrica de avaliação é **error**, você define o objetivo como *error*.\n",
    "\n",
    "```\n",
    "objective_metric_name = 'validation:error'\n",
    "objective_type = 'Minimize'\n",
    "```\n",
    "\n",
    "Por fim, você executa o trabalho de ajuste.\n",
    "\n",
    "```\n",
    "tuner = HyperparameterTuner(xgb,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs=10, # Defina isso como 10 ou acima dependendo do orçamento e do tempo disponível.\n",
    "                            max_parallel_jobs=1,\n",
    "                            objective_type=objective_type,\n",
    "                            early_stopping_type='Auto')\n",
    "\n",
    "tuner.fit(inputs=data_channels, include_cls_metadata=False)\n",
    "tuner.wait()\n",
    "```\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i class=\"fas fa-exclamation-triangle\" style=\"color:red\"></i> Aguarde até que o trabalho de treinamento seja concluído. Isso pode levar até **45** minutos. Enquanto você aguarda, observe o status do trabalho no console, conforme descrito nas instruções a seguir.\n",
    "\n",
    "**Para monitorar trabalhos de otimização de hiperparâmetros:**  \n",
    "\n",
    "1. No Console de gerenciamento da AWS, no menu **Services** (Serviços), escolha **Amazon SageMaker**.  \n",
    "2. Escolha **Training > Hyperparameter tuning jobs** (Treinamento > Trabalhos de ajuste de hiperparâmetros).  \n",
    "3. Você pode verificar o status de cada trabalho de ajuste de hiperparâmetros, seu valor de métrica objetiva e seus logs.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depois que o trabalho de treinamento for concluído, verifique o trabalho e certifique-se de que ele tenha sido concluído com êxito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.client('sagemaker').describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.job_name)['HyperParameterTuningJobStatus']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 3: Investigação dos resultados do trabalho de ajuste (tuning jobs)\n",
    "\n",
    "Agora que o trabalho está concluído, deve haver 10 trabalhos (jobs) concluídos. Um dos trabalhos (jobs) deve ser marcado como o me.lhor.\n",
    "\n",
    "Você pode examinar as métricas obtendo *HyperparameterTuningJobAnalytics* e carregando esses dados em um DataFrame do pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from sagemaker.analytics import HyperparameterTuningJobAnalytics\n",
    "\n",
    "tuner_analytics = HyperparameterTuningJobAnalytics(tuner.latest_tuning_job.name, sagemaker_session=sagemaker.Session())\n",
    "\n",
    "df_tuning_job_analytics = tuner_analytics.dataframe()\n",
    "\n",
    "# Sort the tuning job analytics by the final metrics value\n",
    "df_tuning_job_analytics.sort_values(\n",
    "    by=['FinalObjectiveValue'],\n",
    "    inplace=True,\n",
    "    ascending=False if tuner.objective_type == \"Maximize\" else True)\n",
    "\n",
    "# Show detailed analytics for the top 20 models\n",
    "df_tuning_job_analytics.head(20)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você deve ser capaz de ver os hiperparâmetros que foram usados para cada job, juntamente com a pontuação. Você pode usar esses parâmetros e criar um modelo ou pode obter o melhor modelo do trabalho de ajuste de hiperparâmetros (hyperparameter tuning job)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attached_tuner = HyperparameterTuner.attach(tuner.latest_tuning_job.name, sagemaker_session=sagemaker.Session())\n",
    "best_training_job = attached_tuner.best_training_job()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, você deve usar o melhor trabalho de treinamento e criar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "algo_estimator = Estimator.attach(best_training_job)\n",
    "\n",
    "best_algo_model = algo_estimator.create_model(env={'SAGEMAKER_DEFAULT_INVOCATIONS_ACCEPT':\"text/csv\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, você pode usar o método de transformação (transform) para executar uma predição em lote usando seus dados de teste. Lembre-se de que os dados de teste são dados que o modelo nunca viu antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch_output = \"s3://{}/{}/batch-out/\".format(bucket,prefix)\n",
    "batch_input = \"s3://{}/{}/batch-in/{}\".format(bucket,prefix,batch_X_file)\n",
    "\n",
    "xgb_transformer = best_algo_model.transformer(instance_count=1,\n",
    "                                       instance_type='ml.m4.xlarge',\n",
    "                                       strategy='MultiRecord',\n",
    "                                       assemble_with='Line',\n",
    "                                       output_path=batch_output)\n",
    "\n",
    "\n",
    "xgb_transformer.transform(data=batch_input,\n",
    "                         data_type='S3Prefix',\n",
    "                         content_type='text/csv',\n",
    "                         split_type='Line')\n",
    "xgb_transformer.wait(logs=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenha o alvo predito e os rótulos de teste do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=bucket, Key=\"{}/batch-out/{}\".format(prefix,'batch-in.csv.out'))\n",
    "best_target_predicted = pd.read_csv(io.BytesIO(obj['Body'].read()),names=['class'])\n",
    "\n",
    "def binary_convert(x):\n",
    "    threshold = 0.5\n",
    "    if x > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "best_target_predicted_binary = best_target_predicted['class'].apply(binary_convert)\n",
    "test_labels = test.iloc[:,0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plote uma matriz de confusão para `best_target_predicted` e `test_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(test_labels, best_target_predicted_binary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plote o gráfico ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc(test_labels, best_target_predicted_binary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pergunta:** Como esses resultados diferem do original? Esses resultados são melhores ou piores? \n",
    "\n",
    "Talvez você nem sempre veja uma melhoria. Há alguns motivos para esse resultado:\n",
    "\n",
    "- O modelo já pode ser bom desde a passagem inicial (o que conta como *bom* é subjetivo).\n",
    "- Você não tem uma grande quantidade de dados para treinar.\n",
    "- Você está usando um *subconjunto* dos intervalos de ajuste de hiperparâmetros para economizar tempo neste laboratório.\n",
    "\n",
    "Aumentar os intervalos de hiperparâmetros (conforme recomendado pela documentação) e executar mais de 30 trabalhos (jobs) normalmente melhorará o modelo. No entanto, esse processo demorará de 2 a 3 horas para ser concluído."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parabéns!\n",
    "\n",
    "Você concluiu este laboratório e agora pode encerrá-lo seguindo as instruções do guia do laboratório.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
