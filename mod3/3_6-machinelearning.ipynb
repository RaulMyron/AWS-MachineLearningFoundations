{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratório 3.6 - Notebook do aluno"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visão geral\n",
    "\n",
    "Este laboratório é uma continuação dos laboratórios guiados do Módulo 3.\n",
    "\n",
    "Neste laboratório, você avaliará o modelo treinado em módulos anteriores. Você também calculará métricas com base nos resultados dos dados de teste.\n",
    "\n",
    "\n",
    "## Introdução ao cenário do negócio\n",
    "\n",
    "Você trabalha para um provedor de serviços médicos e deseja melhorar a detecção de anormalidades em pacientes ortopédicos. \n",
    "\n",
    "Você tem a incumbência de resolver esse problema usando machine learning (ML). Você tem acesso a um conjunto de dados que contém seis funcionalidades biomecânicas (componentes) e um alvo (target) de *normal* (normal) ou *abnormal* (anormal). Você pode usar esse conjunto de dados (dataset) para treinar um modelo de ML para prever se um paciente terá uma anomalia.\n",
    "\n",
    "\n",
    "## Sobre esse conjunto de dados (dataset)\n",
    "\n",
    "Esse conjunto de dados biomédicos foi criado pelo Dr. Henrique da Mota durante um período de residência médica no Group of Applied Research in Orthopaedics (GARO) do Centre Médico-Chirurgical de Réadaptation des Massues em Lyon, na França. Os dados foram organizados em duas tarefas de classificação diferentes, mas relacionadas. \n",
    "\n",
    "A primeira tarefa consiste em classificar os pacientes como pertencentes a uma das três categorias a seguir: \n",
    "\n",
    "- *Normal* (Normal) (100 pacientes)\n",
    "- *Disk Hernia* (Hérnia de disco) (60 pacientes)\n",
    "- *Spondylolisthesis* (Espondilolistese) (150 pacientes)\n",
    "\n",
    "Para a segunda tarefa, as categorias *Disk Hernia* (Hérnia de disco) e *Spondylolisthesis* (Espondilolistese) foram mescladas em uma única categoria, rotulada como *abnormal* (anormal). Portanto, a segunda tarefa consiste em classificar os pacientes como pertencentes a uma das categorias: *Normal* (Normal) (100 pacientes) ou *Abnormal* (Anormal) (210 pacientes).\n",
    "\n",
    "\n",
    "## Informações dos atributos\n",
    "\n",
    "Cada paciente é representado no conjunto de dados (dataset) por seis atributos biomecânicos derivados da forma e da orientação da pelve e da coluna lombar (nesta ordem): \n",
    "\n",
    "- Incidência pélvica\n",
    "- Inclinação pélvica\n",
    "- Ângulo da lordose lombar\n",
    "- Inclinação sacral\n",
    "- Raio pélvico\n",
    "- Grau de espondilolistese\n",
    "\n",
    "A convenção a seguir é usada para os rótulos de classe (labels): \n",
    "- DH (hérnia de disco)\n",
    "- Espondilolistese (SL)\n",
    "- Normal (NO) \n",
    "- Anormal (AB)\n",
    "\n",
    "Para obter mais informações sobre esse conjunto de dados (dataset), consulte a [página da Web Conjunto de dados de coluna vertebral](http://archive.ics.uci.edu/ml/datasets/Vertebral+Column).\n",
    "\n",
    "\n",
    "## Atribuições do conjunto de dados (dataset)\n",
    "\n",
    "Esse conjunto de dados (dataset) foi obtido de:\n",
    "Dua, D. e Graff, C. (2019). repositório UCI Machine Learning (http://archive.ics.uci.edu/ml). Irvine, CA: University of California, School of Information and Computer Science.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuração do laboratório\n",
    "\n",
    "Como a solução é dividida em vários laboratórios no módulo, você executará as seguintes células para poder carregar os dados e treinar o modelo a ser implantado.\n",
    "\n",
    "**Observação:** a configuração pode demorar até cinco minutos para ser concluída."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação dos dados e treinamento do modelo\n",
    "\n",
    "Ao executar as células a seguir, os dados serão importados e estarão prontos para uso. \n",
    "\n",
    "**Observação:** as células a seguir representam as principais etapas dos laboratórios anteriores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket='c117523a2804662l6883846t1w198478609102-labbucket-ojfl3mti4wra'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, requests, zipfile, io\n",
    "warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_zip = 'http://archive.ics.uci.edu/ml/machine-learning-databases/00212/vertebral_column_data.zip'\n",
    "r = requests.get(f_zip, stream=True)\n",
    "Vertebral_zip = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "Vertebral_zip.extractall()\n",
    "\n",
    "data = arff.loadarff('column_2C_weka.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "\n",
    "class_mapper = {b'Abnormal':1,b'Normal':0}\n",
    "df['class']=df['class'].replace(class_mapper)\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df = df[cols]\n",
    "\n",
    "train, test_and_validate = train_test_split(df, test_size=0.2, random_state=42, stratify=df['class'])\n",
    "test, validate = train_test_split(test_and_validate, test_size=0.5, random_state=42, stratify=test_and_validate['class'])\n",
    "\n",
    "prefix='lab3'\n",
    "\n",
    "train_file='vertebral_train.csv'\n",
    "test_file='vertebral_test.csv'\n",
    "validate_file='vertebral_validate.csv'\n",
    "\n",
    "s3_resource = boto3.Session().resource('s3')\n",
    "def upload_s3_csv(filename, folder, dataframe):\n",
    "    csv_buffer = io.StringIO()\n",
    "    dataframe.to_csv(csv_buffer, header=False, index=False )\n",
    "    s3_resource.Bucket(bucket).Object(os.path.join(prefix, folder, filename)).put(Body=csv_buffer.getvalue())\n",
    "\n",
    "upload_s3_csv(train_file, 'train', train)\n",
    "upload_s3_csv(test_file, 'test', test)\n",
    "upload_s3_csv(validate_file, 'validate', validate)\n",
    "\n",
    "container = retrieve('xgboost',boto3.Session().region_name,'1.0-1')\n",
    "\n",
    "hyperparams={\"num_round\":\"42\",\n",
    "             \"eval_metric\": \"auc\",\n",
    "             \"objective\": \"binary:logistic\"}\n",
    "\n",
    "s3_output_location=\"s3://{}/{}/output/\".format(bucket,prefix)\n",
    "xgb_model=sagemaker.estimator.Estimator(container,\n",
    "                                       sagemaker.get_execution_role(),\n",
    "                                       instance_count=1,\n",
    "                                       instance_type='ml.m4.xlarge',\n",
    "                                       output_path=s3_output_location,\n",
    "                                        hyperparameters=hyperparams,\n",
    "                                        sagemaker_session=sagemaker.Session())\n",
    "\n",
    "train_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/train/\".format(bucket,prefix,train_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "validate_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/validate/\".format(bucket,prefix,validate_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "data_channels = {'train': train_channel, 'validation': validate_channel}\n",
    "\n",
    "xgb_model.fit(inputs=data_channels, logs=False)\n",
    "\n",
    "batch_X = test.iloc[:,1:];\n",
    "\n",
    "batch_X_file='batch-in.csv'\n",
    "upload_s3_csv(batch_X_file, 'batch-in', batch_X)\n",
    "\n",
    "batch_output = \"s3://{}/{}/batch-out/\".format(bucket,prefix)\n",
    "batch_input = \"s3://{}/{}/batch-in/{}\".format(bucket,prefix,batch_X_file)\n",
    "\n",
    "xgb_transformer = xgb_model.transformer(instance_count=1,\n",
    "                                       instance_type='ml.m4.xlarge',\n",
    "                                       strategy='MultiRecord',\n",
    "                                       assemble_with='Line',\n",
    "                                       output_path=batch_output)\n",
    "\n",
    "xgb_transformer.transform(data=batch_input,\n",
    "                         data_type='S3Prefix',\n",
    "                         content_type='text/csv',\n",
    "                         split_type='Line')\n",
    "xgb_transformer.wait()\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=bucket, Key=\"{}/batch-out/{}\".format(prefix,'batch-in.csv.out'))\n",
    "target_predicted = pd.read_csv(io.BytesIO(obj['Body'].read()),names=['class'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 1: Explorando os resultados\n",
    "\n",
    "A saída do modelo será uma probabilidade. Você deve, primeiramente, converter essa probabilidade em uma das duas classes, *0* ou *1*. Para fazer isso, você pode criar uma função para executar a conversão. Observe o uso do limite na função."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_convert(x):\n",
    "    threshold = 0.3\n",
    "    if x > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "target_predicted_binary = target_predicted['class'].apply(binary_convert)\n",
    "\n",
    "print(target_predicted_binary.head(5))\n",
    "test.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nesses resultados, você pode observar que o modelo inicial pode não ser tão bom. É difícil saber pela comparação de alguns valores.\n",
    "\n",
    "Em seguida, você gerará algumas métricas para ver o desempenho do modelo.\n",
    "\n",
    "\n",
    "# Etapa 2: Criando de uma matriz de confusão (confusion matrix)\n",
    "\n",
    "Uma *matriz de confusão* (confusion matrix) é uma das principais maneiras de medir o desempenho de um modelo de classificação. É uma tabela que mapeia as previsões corretas e incorretas. Depois de calcular uma matriz de confusão (confusion matrix) para o modelo, você poderá gerar várias outras estatísticas. No entanto, você começará criando apenas a matriz de confusão (confusion matrix).\n",
    "\n",
    "Para criar uma matriz de confusão (confusion matrix), você precisa dos valores algo (target) dos dados de teste *e* do valor predito. \n",
    "\n",
    "Obtenha os alvos (targets) do DataFrame de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test.iloc[:,0]\n",
    "test_labels.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, você pode usar a biblioteca *scikit-learn*, que contém uma função para criar uma matriz de confusão (confusion matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matrix = confusion_matrix(test_labels, target_predicted_binary)\n",
    "df_confusion = pd.DataFrame(matrix, index=['Nnormal','Abnormal'],columns=['Normal','Abnormal'])\n",
    "\n",
    "df_confusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados variam, mas você deverá ter resultados semelhantes a este exemplo:\n",
    "\n",
    "_ | Abnormal | Normal (_ | Anormal | Normal)\n",
    "---------- | ----: | ----:\n",
    "Normal | 7 | 3\n",
    "Abnormal | 3 | 18 (Anormal | 3 | 18)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tabela anterior mostra que o modelo previu corretamente os valores *7 Normal* (7 Normais) e *18 Abnormal* (18 Anormais). No entanto, ele previu incorretamente os valores *3 Normal* (3 Normais) e *3 Abnormal* (3 Anormais). \n",
    "\n",
    "Ao usar as bibliotecas Python *seaborn* e *matplotlib*, você pode plotar esses valores em um gráfico para facilitar a leitura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colormap = sns.color_palette(\"BrBG\", 10)\n",
    "sns.heatmap(df_confusion, annot=True, cbar=None, cmap=colormap)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dica:** se o gráfico não for exibido na primeira vez, tente executar a célula novamente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se esses resultados forem suficientemente bons para sua aplicação, isso significa que o modelo pode estar suficientemente bom. No entanto, como há consequências da previsão incorreta dos valores *Normal* (Normais) (ou seja, nenhuma anomalia foi encontrada quando realmente houve uma), o foco deve ser a redução desse resultado."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 3: Cálculo dos dados estatísticos de desempenho"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se você quiser comparar esse modelo com o próximo modelo que criar, precisará de algumas métricas que possam ser registradas. Para um problema de classificação binária, os dados da matriz de confusão (confusion matrix) podem ser usados para calcular várias métricas.\n",
    "\n",
    "Para começar, extraia os valores das células da matriz de confusão (confusion matrix) em variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(test_labels, target_predicted_binary).ravel()\n",
    "\n",
    "print(f\"True Negative (TN) : {TN}\")\n",
    "print(f\"False Positive (FP): {FP}\")\n",
    "print(f\"False Negative (FN): {FN}\")\n",
    "print(f\"True Positive (TP) : {TP}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, você pode calcular alguns dados estatísticos.\n",
    "\n",
    "\n",
    "### Sensibilidade\n",
    "\n",
    "A *Sensibilidade* (sensitivity) também é conhecida como *taxa de acertos* *hit rate* , *recall* ou *taxa de verdadeiros positivos (TPR)*. Ela mede a proporção dos verdadeiros positivos que são identificados corretamente.\n",
    "\n",
    "Neste exemplo, a sensibilidade é *a probabilidade de detecção de uma anormalidade em pacientes com uma anormalidade*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "Sensitivity  = float(TP)/(TP+FN)*100\n",
    "print(f\"Sensitivity or TPR: {Sensitivity}%\")  \n",
    "print(f\"There is a {Sensitivity}% chance of detecting patients with an abnormality have an abnormality\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pergunta:** A sensibilidade é suficientemente boa para este cenário?\n",
    "\n",
    "\n",
    "### Especificidade\n",
    "\n",
    "O próximo dado estatístico é a *especificidade* (specificity), que também é conhecida como *verdadeiro negativo*. Ela mede a proporção dos verdadeiros negativos que são identificados corretamente.\n",
    "\n",
    "Neste exemplo, a especificidade é *a probabilidade de detecção de normalidade em pacientes normais*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specificity or true negative rate\n",
    "Specificity  = float(TN)/(TN+FP)*100\n",
    "print(f\"Specificity or TNR: {Specificity}%\") \n",
    "print(f\"There is a {Specificity}% chance of detecting normal patients are normal.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pergunta:** Essa especificidade é muito baixa, exatamente correta ou muito alta? Que valor você gostaria de ver aqui, considerando o cenário?\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores preditivos positivos e negativos\n",
    "\n",
    "A *precisão*, ou *valor preditivo positivo*, é a proporção de resultados positivos.\n",
    "\n",
    "Neste exemplo, o valor preditivo positivo é *a probabilidade de que os indivíduos com teste de triagem positivo tenham, realmente, uma anormalidade*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision or positive predictive value\n",
    "Precision = float(TP)/(TP+FP)*100\n",
    "print(f\"Precision: {Precision}%\")  \n",
    "print(f\"You have an abnormality, and the probablity that is correct is {Precision}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O *valor preditivo negativo* é a proporção de resultados negativos.\n",
    "\n",
    "Neste exemplo, o valor preditivo negativo é *a probabilidade de que os indivíduos com teste de triagem negativo tenham, realmente, uma anormalidade*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative predictive value\n",
    "NPV = float(TN)/(TN+FN)*100\n",
    "print(f\"Negative Predictive Value: {NPV}%\") \n",
    "print(f\"You don't have an abnormality, but there is a {NPV}% chance that is incorrect\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pense no impacto desses valores. Se você fosse um paciente, até que ponto você estaria preocupado se o teste para uma anormalidade fosse positivo? Por outro lado, até que ponto você estaria tranquilo se tivesse testado negativo?\n",
    "\n",
    "\n",
    "### Taxa de falsos positivos (false positive rate)\n",
    "\n",
    "A *taxa de falsos positivos (FPR)* (false positive rate) é a probabilidade de um alarme falso ocorrer ou *um resultado positivo ser fornecido quando um valor verdadeiro for negativo*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fall out or false positive rate\n",
    "FPR = float(FP)/(FP+TN)*100\n",
    "print( f\"False Positive Rate: {FPR}%\") \n",
    "print( f\"There is a {FPR}% chance that this positive result is incorrect.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxa de falsos negativos\n",
    "\n",
    "A *taxa de falsos negativos* (false negative rate) - ou *taxa de erro* (miss rate) - é *a probabilidade de que um verdadeiro positivo não seja detectado pelo teste*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False negative rate\n",
    "FNR = float(FN)/(TP+FN)*100\n",
    "print(f\"False Negative Rate: {FNR}%\") \n",
    "print(f\"There is a {FNR}% chance that this negative result is incorrect.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxa de descobertas falsas (False discovery rate)\n",
    "\n",
    "Neste exemplo, a *taxa de descoberta falsa* é *a probabilidade de se prever uma anormalidade quando o paciente não possuir uma*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False discovery rate\n",
    "FDR = float(FP)/(TP+FP)*100\n",
    "print(f\"False Discovery Rate: {FDR}%\" )\n",
    "print(f\"You have an abnormality, but there is a {FDR}% chance this is incorrect.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisão geral\n",
    "\n",
    "Qual a precisão do seu modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall accuracy\n",
    "ACC = float(TP+TN)/(TP+FP+FN+TN)*100\n",
    "print(f\"Accuracy: {ACC}%\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em resumo, você calculou as seguintes métricas do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Sensitivity or TPR: {Sensitivity}%\")    \n",
    "print(f\"Specificity or TNR: {Specificity}%\") \n",
    "print(f\"Precision: {Precision}%\")   \n",
    "print(f\"Negative Predictive Value: {NPV}%\")  \n",
    "print( f\"False Positive Rate: {FPR}%\") \n",
    "print(f\"False Negative Rate: {FNR}%\")  \n",
    "print(f\"False Discovery Rate: {FDR}%\" )\n",
    "print(f\"Accuracy: {ACC}%\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tarefa desafio:** Registre os valores anteriores e, em seguida, volte para a etapa 1 e altere o valor usado para limite (threshold). Os valores que você deverá tentar são *0,25* e *0,75*. \n",
    "\n",
    "Esses valores de limite (threshold) fazem alguma diferença?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 4: Cálculo do AUC-ROC\n",
    "\n",
    "A biblioteca scikit-learn tem funções que podem ajudar você a calcular a *área sob a curva característica de operação do receptor (AUC-ROC)*.\n",
    "\n",
    "- A ROC é uma curva de probabilidade.\n",
    "- A AUC informa o quanto o modelo pode fazer a distinção entre classes. \n",
    "\n",
    "A AUC pode ser calculada. Como você verá no próximo laboratório, ela pode ser usada para medir o desempenho do modelo. \n",
    "\n",
    "Neste exemplo, quanto maior for a AUC, melhor o modelo fará distinção entre pacientes anormais e normais.\n",
    "\n",
    "Dependendo do valor definido para o limite (threshold), a AUC pode mudar. Você pode plotar a AUC usando a probabilidade em vez da classe convertida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test.iloc[:,0];\n",
    "print(\"Validation AUC\", roc_auc_score(test_labels, target_predicted) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalmente, a curva ROC é representada com a TPR em relação à FPR, em que a TPR está no eixo y e a FPR está no eixo x.\n",
    "\n",
    "O scikit-learn tem a função **roc_curve** para ajudar a gerar esses valores para plotagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(test_labels, target_predicted)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % (roc_auc))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    " \n",
    "# create the axis of thresholds (scores)\n",
    "ax2 = plt.gca().twinx()\n",
    "ax2.plot(fpr, thresholds, markeredgecolor='r',linestyle='dashed', color='r')\n",
    "ax2.set_ylabel('Threshold',color='r')\n",
    "ax2.set_ylim([thresholds[-1],thresholds[0]])\n",
    "ax2.set_xlim([fpr[0],fpr[-1]])\n",
    "\n",
    "print(plt.figure())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tarefa de desafio:** Atualize o código anterior para usar *target_predicted_binary* em vez de *target_predicted*. Como isso altera o gráfico? Qual é o mais útil?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parabéns!\n",
    "\n",
    "Você concluiu este laboratório e agora pode encerrá-lo seguindo as instruções do guia do laboratório."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
