{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratório 3.5 - Notebook do aluno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visão geral\n",
    "\n",
    "Este laboratório é uma continuação dos laboratórios guiados do Módulo 3. \n",
    "\n",
    "Neste laboratório, você implantará um modelo já treinado e executará uma previsão relativa a ele. Em seguida, você excluirá o endpoint e executará uma transformação de lote (batch) no conjunto de dados (dataset) de teste.\n",
    "\n",
    "\n",
    "## Introdução ao cenário do negócio\n",
    "\n",
    "Você trabalha para um provedor de serviços médicos e deseja melhorar a detecção de anormalidades em pacientes ortopédicos. \n",
    "\n",
    "Você tem a incumbência de resolver esse problema usando machine learning (ML). Você tem acesso a um conjunto de dados que contém seis componentes biomecânicos e um alvo (target) de *normal* (normal) ou *abnormal* (anormal). Você pode usar esse conjunto de dados (dataset) para treinar um modelo de ML para prever se um paciente terá uma anomalia.\n",
    "\n",
    "\n",
    "## Sobre esse conjunto de dados (dataset)\n",
    "\n",
    "Esse conjunto de dados (dataset) biomédicos foi criado pelo Dr. Henrique da Mota durante um período de residência médica no Group of Applied Research in Orthopaedics (GARO) do Centre Médico-Chirurgical de Réadaptation des Massues em Lyon, na França. Os dados foram organizados em duas tarefas de classificação diferentes, mas relacionadas. \n",
    "\n",
    "A primeira tarefa consiste em classificar os pacientes como pertencentes a uma das três categorias a seguir: \n",
    "\n",
    "- *Normal* (Normal) (100 pacientes)\n",
    "- *Disk Hernia* (Hérnia de disco) (60 pacientes)\n",
    "- *Spondylolisthesis* (Espondilolistese) (150 pacientes)\n",
    "\n",
    "Para a segunda tarefa, as categorias *Disk Hernia* (Hérnia de disco) e *Spondylolisthesis* (Espondilolistese) foram mescladas em uma única categoria, rotulada como *abnormal* (anormal). Portanto, a segunda tarefa consiste em classificar os pacientes como pertencentes a uma das categorias: *Normal* (Normal) (100 pacientes) ou *Abnormal* (Anormal) (210 pacientes).\n",
    "\n",
    "\n",
    "## Informações dos atributos\n",
    "\n",
    "Cada paciente é representado no conjunto de dados (dataset) por seis atributos biomecânicos derivados da forma e da orientação da pelve e da coluna lombar (nesta ordem): \n",
    "\n",
    "- Incidência pélvica\n",
    "- Inclinação pélvica\n",
    "- Ângulo da lordose lombar\n",
    "- Inclinação sacral\n",
    "- Raio pélvico\n",
    "- Grau de espondilolistese\n",
    "\n",
    "A convenção a seguir é usada para os rótulos de classe (labels): \n",
    "- DH (hérnia de disco)\n",
    "- Espondilolistese (SL)\n",
    "- Normal (NO) \n",
    "- Anormal (AB)\n",
    "\n",
    "Para obter mais informações sobre esse conjunto de dados (dataset), consulte a [página da Web Conjunto de dados de coluna vertebral](http://archive.ics.uci.edu/ml/datasets/Vertebral+Column).\n",
    "\n",
    "\n",
    "## Atribuições do conjunto de dados (dataset)\n",
    "\n",
    "Esse conjunto de dados (dataset) foi obtido de:\n",
    "Dua, D. e Graff, C. (2019). repositório UCI Machine Learning (http://archive.ics.uci.edu/ml). Irvine, CA: University of California, School of Information and Computer Science.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuração do laboratório\n",
    "\n",
    "Como essa solução é dividida em vários laboratórios no módulo, você executará as seguintes células para poder carregar os dados e treinar o modelo a ser implantado.\n",
    "\n",
    "**Observação:** A configuração pode demorar até 5 minutos para ser concluída."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação de dados\n",
    "\n",
    "Ao executar as células a seguir, os dados serão importados e estarão prontos para uso. \n",
    "\n",
    "**Observação:** As células a seguir representam as principais etapas dos laboratórios anteriores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket='c117523a2804660l6883286t1w729814179638-labbucket-s5gmtv0pvzp0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, requests, zipfile, io\n",
    "warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_zip = 'http://archive.ics.uci.edu/ml/machine-learning-databases/00212/vertebral_column_data.zip'\n",
    "r = requests.get(f_zip, stream=True)\n",
    "Vertebral_zip = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "Vertebral_zip.extractall()\n",
    "\n",
    "data = arff.loadarff('column_2C_weka.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "\n",
    "class_mapper = {b'Abnormal':1,b'Normal':0}\n",
    "df['class']=df['class'].replace(class_mapper)\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "df = df[cols]\n",
    "\n",
    "train, test_and_validate = train_test_split(df, test_size=0.2, random_state=42, stratify=df['class'])\n",
    "test, validate = train_test_split(test_and_validate, test_size=0.5, random_state=42, stratify=test_and_validate['class'])\n",
    "\n",
    "prefix='lab3'\n",
    "\n",
    "train_file='vertebral_train.csv'\n",
    "test_file='vertebral_test.csv'\n",
    "validate_file='vertebral_validate.csv'\n",
    "\n",
    "s3_resource = boto3.Session().resource('s3')\n",
    "def upload_s3_csv(filename, folder, dataframe):\n",
    "    csv_buffer = io.StringIO()\n",
    "    dataframe.to_csv(csv_buffer, header=False, index=False )\n",
    "    s3_resource.Bucket(bucket).Object(os.path.join(prefix, folder, filename)).put(Body=csv_buffer.getvalue())\n",
    "\n",
    "upload_s3_csv(train_file, 'train', train)\n",
    "upload_s3_csv(test_file, 'test', test)\n",
    "upload_s3_csv(validate_file, 'validate', validate)\n",
    "\n",
    "container = retrieve('xgboost',boto3.Session().region_name,'1.0-1')\n",
    "\n",
    "hyperparams={\"num_round\":\"42\",\n",
    "             \"eval_metric\": \"auc\",\n",
    "             \"objective\": \"binary:logistic\"}\n",
    "\n",
    "s3_output_location=\"s3://{}/{}/output/\".format(bucket,prefix)\n",
    "xgb_model=sagemaker.estimator.Estimator(container,\n",
    "                                       sagemaker.get_execution_role(),\n",
    "                                       instance_count=1,\n",
    "                                       instance_type='ml.m4.xlarge',\n",
    "                                       output_path=s3_output_location,\n",
    "                                        hyperparameters=hyperparams,\n",
    "                                        sagemaker_session=sagemaker.Session())\n",
    "\n",
    "train_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/train/\".format(bucket,prefix,train_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "validate_channel = sagemaker.inputs.TrainingInput(\n",
    "    \"s3://{}/{}/validate/\".format(bucket,prefix,validate_file),\n",
    "    content_type='text/csv')\n",
    "\n",
    "data_channels = {'train': train_channel, 'validation': validate_channel}\n",
    "\n",
    "xgb_model.fit(inputs=data_channels, logs=False)\n",
    "\n",
    "print('ready for hosting!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 1: Hospedagem do modelo\n",
    "\n",
    "Agora que você tem um modelo treinado, pode hospedá-lo usando os serviços de hospedagem do Amazon SageMaker.\n",
    "\n",
    "A primeira etapa é a implantação do modelo. Como você tem um objeto de modelo,*xgb_model*, pode usar o método **deploy** (implantar). Para este laboratório, você usará uma única instância ml.m4.xlarge.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor = xgb_model.deploy(initial_instance_count=1,\n",
    "                serializer = sagemaker.serializers.CSVSerializer(),\n",
    "                instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 2: Executar predições\n",
    "\n",
    "Agora que tem um modelo implantado, você executará algumas predições.\n",
    "\n",
    "Primeiramente, analise os dados de teste e familiarize-se com eles novamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você tem 31 instâncias, com sete atributos. As primeiras cinco instâncias são:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você não precisa incluir o valor do alvo (classe). Esse preditor pode obter dados no formato CSV (valores separados por vírgula). Portanto, você pode obter a primeira linha *sem a coluna de classe* usando o seguinte código:\n",
    "\n",
    "`test.iloc[:1,1:]` \n",
    "\n",
    "A função **iloc** usa parâmetros de [*rows*,*cols*]\n",
    "\n",
    "Para obter apenas a primeira linha, use `0:1`. Se você deseja obter a linha 2, pode usar `1:2`.\n",
    "\n",
    "Para obter todas as colunas, *exceto* a primeira coluna (*col 0*), use `1:`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = test.iloc[0:1,1:]\n",
    "row.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode converter isso em um arquivo CSV (valores separados por vírgula) e armazenar em um buffer de string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X_csv_buffer = io.StringIO()\n",
    "row.to_csv(batch_X_csv_buffer, header=False, index=False)\n",
    "test_row = batch_X_csv_buffer.getvalue()\n",
    "print(test_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, você pode usar os dados para executar uma predição."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.content_type = 'text/csv'\n",
    "xgb_predictor.predict(test_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O resultado obtido não é *0* nem *1*. Em vez disso, você obtém uma *pontuação de probabilidade* (probability score). Você pode aplicar alguma lógica condicional à pontuação de probabilidade (probability score) para determinar se a resposta deverá ser apresentada como 0 ou 1. Você trabalhará com esse processo quando fizer predições em lote.\n",
    "\n",
    "Por ora, compare o resultado com os dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pergunta:** A predição é precisa?\n",
    "\n",
    "**Tarefa de desafio:** Atualize o código anterior para enviar a segunda linha do conjunto de dados (dataset). Essas previsões estão corretas? Experimente esta tarefa com algumas outras linhas.\n",
    "\n",
    "Pode ser entediante enviar essas linhas uma de cada vez. Você pode elaborar uma função para enviar esses valores em um lote (batch), mas o SageMaker já tem um recurso de lote (batch). Você examinará esse recurso em seguida. No entanto, antes de fazer isso, você encerrará o modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 3: Encerrar o modelo implantado\n",
    "\n",
    "Para excluir o endpoint, use a função **delete_endpoint** no preditor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 4: Realizar uma transformação em lote (batch)\n",
    "\n",
    "Quando você está no ciclo de engenharia de treinamento-teste dos componentes (features), deseja testar seus conjuntos de holdout (holdout sets) ou teste (test sets) em comparação com o modelo. Depois, você pode usar esses resultados para calcular métricas. Você pode implantar um endpoint como fez antes, mas deve se lembrar de excluir o endpoint. No entanto, existe uma maneira mais eficiente.\n",
    "\n",
    "Você pode usar o método transformer no modelo para obter um objeto transformer (transformer object). Em seguida, você pode usar o método transformer deste objeto para executar uma predição em todo o conjunto de dados de teste (test dataset). O SageMaker: \n",
    "\n",
    "- Gerará uma instância com o modelo\n",
    "- Executará uma predição em todos os valores de entrada\n",
    "- Gravará esses valores no Amazon Simple Storage Service (Amazon S3) \n",
    "- Finalmente, encerrará a instância\n",
    "\n",
    "Você poderá começar transformando seus dados em um arquivo CSV, o qual o objeto transformer pode usar como entrada. Dessa vez, você usará **iloc** para obter todas as linhas e todas as colunas, *exceto* a primeira coluna.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X = test.iloc[:,1:];\n",
    "batch_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, grave seus dados em um arquivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_X_file='batch-in.csv'\n",
    "upload_s3_csv(batch_X_file, 'batch-in', batch_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, antes de executar uma transformação, configure o transformer com o arquivo de entrada, o local de saída e o tipo de instância."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_output = \"s3://{}/{}/batch-out/\".format(bucket,prefix)\n",
    "batch_input = \"s3://{}/{}/batch-in/{}\".format(bucket,prefix,batch_X_file)\n",
    "\n",
    "xgb_transformer = xgb_model.transformer(instance_count=1,\n",
    "                                       instance_type='ml.m4.xlarge',\n",
    "                                       strategy='MultiRecord',\n",
    "                                       assemble_with='Line',\n",
    "                                       output_path=batch_output)\n",
    "\n",
    "xgb_transformer.transform(data=batch_input,\n",
    "                         data_type='S3Prefix',\n",
    "                         content_type='text/csv',\n",
    "                         split_type='Line')\n",
    "xgb_transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a conclusão da transformação, você poderá fazer o download dos resultados do Amazon S3 e compará-los com a entrada.\n",
    "\n",
    "Primeiramente, faça o download da saída do Amazon S3 e carregue-a em um DataFrame do pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=bucket, Key=\"{}/batch-out/{}\".format(prefix,'batch-in.csv.out'))\n",
    "target_predicted = pd.read_csv(io.BytesIO(obj['Body'].read()),',',names=['class'])\n",
    "target_predicted.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode usar uma função para converter a probabilidade em *0* ou *1*.\n",
    "\n",
    "A primeira saída da tabela serão os *predicted values* (valores previstos), e a segunda saída da tabela serão os *original test data* (dados de teste originais)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_convert(x):\n",
    "    threshold = 0.65\n",
    "    if x > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "target_predicted['binary'] = target_predicted['class'].apply(binary_convert)\n",
    "\n",
    "print(target_predicted.head(10))\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observação:** O *limite* da função **binary_convert** é definido como *0,65*.\n",
    "\n",
    "**Tarefa desafio:** experimente alterar o valor do limite (threshold). Isso afeta os resultados?\n",
    "\n",
    "**Observação:** O modelo inicial pode não ser bom. Você gerará algumas métricas no próximo laboratório antes de ajustar o modelo no laboratório final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parabéns!\n",
    "\n",
    "Você concluiu este laboratório e agora pode encerrá-lo seguindo as instruções do guia do laboratório."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda5237872c3cf14727adbe027fe81399e0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
